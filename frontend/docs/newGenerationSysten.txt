Architecture: The "Smart Template" Engine
1. The Core Philosophy
We do not ask the AI to "draw" the banner. We ask the AI to configure a banner.
The AI (OpenAI GPT) acts as the Creative Director. It decides what to say, which colors to use, and where to place elements.
The Code (React/CSS) acts as the Typesetter. It handles font rendering, padding, margins, and alignment.
The Image Gen (OpenAI GPT-image-1, fallback to Pollinations) acts as the Photographer. It provides the raw background texture.
2. The Generation Pipeline (The "3-Step Flow")
Step 1: The Director (OpenAI GPT)
User Input: "I'm a backend engineer looking for freelance work. I like dark themes."

We send this to OpenAI GPT with a strict system prompt. GPT does not return chat; it returns a JSON Configuration Object.
It writes the headline ("Backend Architecture Scaled").
It writes the subtext ("Node.js • Python • System Design").
It selects a visual theme ("Dark Mode").
It constructs a prompt for the background ("Abstract server rack data flow, cybernetic, dark blue, blurred").
Step 2: The Photographer (OpenAI GPT-image-1, fallback to Pollinations.ai)
The frontend takes the background prompt from Step 1 and calls the OpenAI GPT-image-1 API to generate the image. If it fails, it falls back to constructing a Pollinations URL.
Zero Latency Trick: We do not wait for the image to "download." We just inject the URL into the browser.
URL: For GPT-image-1, use OpenAI API; fallback URL: https://image.pollinations.ai/prompt/abstract%20server%20rack...?width=1584&height=396&nologo=true
Step 3: The Assembler (React Component)
The frontend loads a pre-built "Master Template".
It injects the text from Step 1.
It applies the CSS colors from Step 1.
It loads the Background URL from Step 2.
Result: A fully rendered, crisp HTML banner that the user can edit instantly.
3. The "Modern Design" Strategy (How to ensure quality)
If you let AI write raw HTML/CSS from scratch, it will often break or look like a website from 1999. Instead, we use a "Props Injection" System.

You will pre-code 3-5 High-Quality React Components (The Templates). The AI simply chooses which one to use and fills in the blanks.

The Master Templates
"The Minimalist": Clean white/black background, heavy bold typography, centered text. (Best for Executives).
"The Startup": Split layout. Text on left, abstract 3D shape on right. Vibrant accent color. (Best for Founders).
"The Tech": Dark mode, monospaced font, glowing background elements, glassmorphism card for text. (Best for Developers).
The "Modernizer" Layer (CSS Tricks)
To make the designs look "Pro" automatically, apply these rules in your React code:
The Overlay: Always put a CSS linear-gradient (e.g., black to transparent) over the AI background image but under the text. This ensures text is always readable, even if the image is busy.
The Glass Effect: Use backdrop-filter: blur(10px) on text containers.
Dynamic Font Sizing: Use CSS clamp() or container queries so the text perfectly fills the space without overflowing.
4. Data Structure (The JSON Schema)
This is the exact contract between your AI and your Frontend. GPT must output this format.

JSON
{
  "template_id": "tech_split_modern", 
  "content": {
    "headline": "Scalable Backend Systems",
    "subheadline": "Expert Python & Go Developer available for contract.",
    "cta": "hire.me/developer"
  },
  "design": {
    "primary_color": "#00ff88",
    "secondary_color": "#1a1a1a",
    "font_family": "Fira Code",
    "text_alignment": "left"
  },
  "assets": {
    "background_prompt": "matrix code rain, dark green and black, 4k, soft focus, abstract",
    "background_style": "technological"
  }
}
5. Cost & Speed Analysis (The Zero-Budget Win)
Component	Cost	Speed	Quality
Logic (OpenAI GPT)	$0 (Credits System)	~1.5 Seconds	High (JSON is easy for LLMs)
Assets (GPT-image-1, fallback Pollinations)	$0 (Credits/API)	~2.0 Seconds	High (Better quality with fallback)
Render (React)	$0 (Client Side)	0.1 Seconds	Perfect (Vector text, no artifacts)
Storage (Supabase)	$0 (Free Tier)	N/A	High (Only saving text data)
Total	**$0.00**	< 4 Seconds	Pro Standard
6. User Editing Workflow (The "No-Regret" Engine)
Since we are generating Code (React State), not a static Image, the user can fix mistakes instantly.
Generation: User sees the banner.
Edit: "The headline is too long." -> User clicks the text and types. (Impossible with DALL-E).
Swap: "I hate the background." -> User clicks "Regenerate Background." We call GPT-image-1, fallback to Pollinations (Cost: $0), not GPT.
Export: User clicks "Download."
Technique: Use html-to-image (library).
The browser takes a high-res screenshot of the <div>.
User gets a sharp PNG.
