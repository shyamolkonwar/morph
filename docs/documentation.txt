# **Project Architecture & Documentation**

## **1. System Overview**

* **Goal:** A SaaS platform to generate multi-format banners (LinkedIn, YouTube) and carousels using AI.
* **Core Philosophy:** "Hybrid Generation" â€” AI generates the assets (copy + background images), while code (Next.js/React) handles the precise layout and typography.
* **Target Output:** High-resolution PNG/JPG files exported from React components.

---

## **2. Technology Stack**

* **Frontend & Backend:** **Next.js** (App Router, Server Actions).
* **Text & Logic Engine:** **OpenAI GPT-4o** (for copywriting, JSON structuring, and layout decisions).
* **Image Generation Engine:** **Nano Banana Pro** (Google Gemini 3 Pro Image Preview) via Google Gen AI SDK.
* **Database & Auth:** **Supabase** (PostgreSQL, Auth, Storage).
* **Rendering:** **Puppeteer** (server-side headless browser) or **@vercel/og** for image snapshotting.

---

## **3. Architecture Diagrams**

### **3.1 Data Flow**

1. **User Input:** User types a prompt (e.g., "LinkedIn banner for a Data Scientist").
2. **Orchestrator (Next.js):** Sends prompt to **GPT-4o**.
3. **Structured Plan:** GPT-4o returns a JSON object containing:
* Headline/Subtext
* Color Palette (Hex codes)
* Image Prompt (optimized for Nano Banana Pro)
* Layout Choice (e.g., "split_left", "center_hero")


4. **Asset Generation:** Next.js sends the *Image Prompt* to **Nano Banana Pro API**.
5. **Assembly:** Next.js combines the *returned Image URL* + *GPT-4o Text* into a React Component.
6. **Export:** The component is rendered server-side and snapshotted into a downloadable image.

---

## **4. API Integration Strategy**

### **A. OpenAI GPT-4o (The Architect)**

* **Role:** Copywriter & Designer. It does not generate the image; it generates the *instructions* for the image.
* **Implementation:**
* Use `response_format: { type: "json_object" }`.
* **System Prompt:** "You are a UI Designer. You output JSON only. Define typography, colors, and an image description for Nano Banana Pro."


* **Output Schema Example:**
```json
{
  "headline": "Mastering Python",
  "subheadline": "From Zero to Hero",
  "theme": {
    "bg_color": "#0f172a",
    "text_color": "#ffffff",
    "accent_color": "#38bdf8"
  },
  "image_prompt": "Futuristic python snake made of glowing circuit boards, cybernetic style, high resolution, minimalist background",
  "layout_id": "modern_split_right"
}

```



### **B. Nano Banana Pro / Gemini 3 Pro Image (The Artist)**

* **Role:** Background & Asset Generator.
* **Why this model?** It excels at text rendering (if you need text inside the image itself) and adhering to complex instructions better than standard diffusion models.
* **Implementation:**
* Library: `google-genai` SDK.
* Model ID: `gemini-3-pro-image-preview` (or current equivalent alias).
* **Settings:**
* `aspect_ratio`: Dynamically set based on user intent (e.g., `16:9` for YouTube, `4:1` for LinkedIn).
* `safety_settings`: Standard block settings to prevent misuse.




* **Storage:** The API returns a raw image or URL. You must upload this immediately to **Supabase Storage** to persist it.

---

## **5. Database Schema (Supabase)**

You need three primary tables to manage user projects.

### **Table: `users**`

* Managed automatically by Supabase Auth.

### **Table: `projects**`

* `id` (UUID, PK)
* `user_id` (FK -> auth.users)
* `title` (String)
* `type` (Enum: 'linkedin_carousel', 'linkedin_banner', 'youtube_thumbnail')
* `status` (Enum: 'generating', 'completed', 'failed')
* `created_at` (Timestamp)

### **Table: `generations**`

* `id` (UUID, PK)
* `project_id` (FK -> projects)
* `copy_json` (JSONB) - *Stores the GPT-4o output*
* `image_url` (Text) - *Supabase Storage URL for the background*
* `final_output_url` (Text) - *The generated PNG link*

---

## **6. The Rendering Engine (The "Secret Sauce")**

To "fit every size," you cannot rely on AI to generate the full image. You must use code.

### **The "Smart Component" System**

Create a generic React component called `DynamicCanvas`.

1. **Inputs:** `width`, `height`, `data` (JSON from GPT-4o).
2. **Container Query:** Use CSS `container-type: size`.
3. **Logic:**
* If `width > 1200` (LinkedIn Banner): Layout = Horizontal Row (Text Left, Image Right).
* If `aspect-ratio ~ 1:1` (Instagram/Carousel): Layout = Stacked Column (Image Top, Text Bottom).
* **Text Scaling:** Use viewport units (`vw`) or a text-fitting library so text never overflows.



### **Exporting to Image**

* **Option A (Recommended for MVP):** Use **Vercel OG** (`@vercel/og`). It allows you to generate images using HTML/CSS directly in an API route.
* **Option B (High Fidelity):** Run **Puppeteer** in a server action. It opens a headless Chrome browser, renders your `DynamicCanvas`, and takes a screenshot.

---

## **7. Step-by-Step Build Order**

1. **Setup Supabase:** Create project, enable Auth (Google/Email), create Storage bucket named `generated-assets`.
2. **Frontend Skeleton:** Initialize Next.js. Create a dashboard to view "Projects".
3. **GPT-4o Integration:** Build an API route that accepts a prompt and returns the JSON structure.
4. **Nano Banana Integration:** Build a service that takes the `image_prompt` from step 3, calls Google Gemini, and uploads the result to Supabase Storage.
5. **Canvas Builder:** Create the React component that takes the text + image and visualizes it.
6. **Export Pipeline:** Implement `@vercel/og` to turn that React component into a downloadable URL.

## **8. Key Challenges & Solutions**

* **Text Readability:** AI generated backgrounds are often busy.
* *Solution:* Always apply a CSS overlay (gradient or semi-transparent black layer) behind the text area in your React component.


* **Hallucinations:** GPT-4o might suggest a layout that doesn't exist.
* *Solution:* Use Typescript interfaces to strictly validate the JSON return. If `layout_id` is invalid, fallback to "default".


* **Latency:** Image generation takes 5-10 seconds.
* *Solution:* Use **React Server Actions** with `useOptimistic` or a loading skeleton so the user knows work is happening.